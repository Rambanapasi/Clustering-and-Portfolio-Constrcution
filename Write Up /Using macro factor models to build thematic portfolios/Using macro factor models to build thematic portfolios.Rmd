---
# IMPORTANT: Change settings here, but DO NOT change the spacing.
title: "Guide to Using Partition Clustering to Construct Portfolios "
#subtitle: "This will appear as Right Header"
documentclass: "elsarticle"
Thesis_FP: FALSE
# Entry1: "An unbelievable study with a title spanning multiple lines."
# Entry2: "\\textbf{Some Guy}" # textbf for bold
# Entry3: "A thesis submitted toward the degree of Doctor of Philosophy"
# Uni_Logo: Tex/Logo.png # Place a logo in the indicated location (from your root, e.g. defaults to ~/Tex/Logo.png) and uncomment this line. Leave uncommented for no image
# Logo_width: 0.3 # If using a logo - use this to set width (size) of image
# Entry4: "Under the supervision of: \\vfill Prof. Joe Smith and Dr. Frank Smith"
# Entry5: "Stellenbosch University"
# Entry6: April 2020
# Entry7:
# Entry8:
# Comment: ----- Follow this pattern for up to 5 authors
AddTitle: TRUE # Use FALSE when submitting to peer reviewed platform. This will remove author names.
Author1: "Gabriel Rambanapasi"  # First Author - note the thanks message displayed as an italic footnote of first page.
Ref1: "Stellenbosch University, Stellenbosch, South Africa" # First Author's Affiliation
Email1: "rambanapasi44\\@gmail.com" # First Author's Email address
# Author2: "John Smith"
# Ref2: "Some other Institution, Cape Town, South Africa"
# Email2: "John\\@gmail.com"
# CommonAffiliation_12: TRUE # If Author 1 and 2 have a common affiliation. Works with _13, _23, etc.
# Author3: "John Doe"
# Email3: "Joe\\@gmail.com"
CorrespAuthor_1: TRUE  # If corresponding author is author 3, e.g., use CorrespAuthor_3: TRUE
keywords: "K-Means\\sep Clustering \\sep Price Momentun \\sep Volatility \\sep Diversification" # Use \\sep to separate
# JELCodes: "L250 \\sep L100"
# ----- Manage headers and footers:
#BottomLFooter: $Title$
#BottomCFooter:
#TopLHeader: \leftmark # Adds section name at topleft. Remove comment to add it.
BottomRFooter: "\\footnotesize Page \\thepage" # Add a '#' before this line to remove footer.
addtoprule: TRUE
addfootrule: TRUE               # Use if footers added. Add '#' to remove line.
# --------- page margins:
margin: 2.3 # Sides
bottom: 2 # bottom
top: 2.5 # Top
HardSet_layout: TRUE # Hard-set the spacing of words in your document. This will stop LaTeX squashing text to fit on pages, e.g.
linenumbers: FALSE # Used when submitting to journal
# ---------- References settings:
# You can download cls format here: https://www.zotero.org/ - simply search for your institution. You can also edit and save cls formats here: https://editor.citationstyles.org/about/
bibliography: Tex/ref.bib       # Do not edit: Keep this naming convention and location.
csl: Tex/harvard-stellenbosch-university.csl # referencing format used.
# By default, the bibliography only displays the cited references. If you want to change this, you can comment out one of the following:
#nocite: '@*' # Add all items in bibliography, whether cited or not
# nocite: |  # add specific references that aren't cited
# ---------- General:
RemovePreprintSubmittedTo: TRUE  # Removes the 'preprint submitted to...' at bottom of titlepage
Journal: ""   # Journal that the paper will be submitting to, if RemovePreprintSubmittedTo is set to TRUE.
toc: FALSE                       # Add a table of contents
numbersections: TRUE             # Should sections (and thus figures and tables) be numbered?
fontsize: 11pt                  # Set fontsize
linestretch: 1.2                # Set distance between lines.
link-citations: TRUE            # This creates dynamic links to the papers in reference list.
### Adding additional latex packages:
# header-includes:
output:
  pdf_document:
    keep_tex: TRUE
    template: Tex/TexDefault.txt
    fig_width: 3.5 # Adjust default figure sizes. This can also be done in the chunks of the text.
    fig_height: 3.5
abstract: |
editor_options: 
  markdown: 
    wrap: 72
---

<!-- First: Set your default preferences for chunk options: -->

<!-- If you want a chunk's code to be printed, set echo = TRUE. message = FALSE stops R printing ugly package loading details in your final paper too. I also suggest setting warning = FALSE and checking for warnings in R, else you might find ugly warnings in your paper. -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE, fig.width = 6, fig.height = 5, fig.pos="H", fig.pos = 'H')

require("pacman")
p_load("tidyquant", "fmxdat", "tidyverse", "PerformanceAnalytics", "lubridate", "DEoptim", "data.table", "covFcatorModel", "gt", "factoextra")

library(huxtable)
library(kableExtra)
library(xtable)
```

<!-- ############################## -->

<!-- # Start Writing here: -->

<!-- ############################## -->

# Introduction \label{Introduction}

-   aim to test momentum via cumulative return
-   use clusters to group high performers, low performers to each group.
-   build a portfolio, and check out returns.
-   compare the underlying thesis with what has happended

# Clustering and Appliactions to Asset Management

Unsupervised machine learning is a type of machine learning that
searches for patterns in datasets with no pre-existing labels and a
minimum of human intervention. One way in which unsupervised learning
can be applied in data science and other quantitive disciplines is
through clustering algorithms. Clustering is the process of grouping
objects based on similar characteristics. The algorithms designed to
cluster, achieve this function by connecting observation through
distances, density of data points, graphs, or various statistical
distributions. For a cluster to have meaning an algorithm has to
maximize intra-cluster similarity and minimize inter-cluster similarity,
such that each cluster contains information that's as dissimilar to
other clusters[@kassambara2017practical]. There exists various forms of
cluster algorithms, each that addresses a broader task of analysis. The
algorithms can be divided into two main types being partitioning
clustering and hierarchical clustering. The major difference between the
divisions of clustering is the partition clustering aims to specify a
predetermined number of clusters whilst does not
[@kassambara2017practical]. Within partition clustering, for data with a
small set of variables, K-means clustering and partitioning around
medoids (PAM) are the most frequently used due to their fast compuation
and simplicity. With K-means, each cluster is represented by the center
or means of the data points belonging to the entire dataset. This makes
the algorithm sensitive to outliers. However with PAM, each cluster is
represented by one of the objects in the cluster. The other partition
clustering algorithm used for datasets with a large number of variables
is Clustering Large Applications (CLARA).

In asset management, key to funds generating superior risk adjusted
returns is efficient portfolio diversification, thus presenting a great
application for partition clustering. Stocks would be separated into
groups through a clustering algorithm to maximize similarity within
groups and minimizes similarity between groups. Thus allowing managers
to select handpick stock to construct a diversified portfolio.
@marvin2015creating use fundamental ratios (turnover and profitability
ratios) weighted equally and K-means clustering to group US technology
stocks listed on the NASDAQ and NYSE. A diversified portfolio is then
constructed based on within cluster stock performance i.e. stock
selected are those that possess the highest Sharpe ratio. Results over a
period of 15 years that included the dot com bubble and the global
financial crises showed that cluster portfolios exhibited more
volatility than the benchmark (S&P 500), however returns to investors
were above the benchmark at multiples ranging from 3.5 to 5.7 times when
earnings are reinvested into the cluster portfolios. @bin2020k uses a
similar approach to @marvin2015creating, however employing a combination
of market ratios and fundamental ratios (price to earnings ratio, return
on assets ratio and asset turnover ratio ). From this study, compared to
the S&P 500, portfolios constructed using market ratios under performed
those that used fundamental ratios.
\newpage

# Data and Methodology

This section describes how we obtain the data set used in the study,
details the clustering process and validating metrics employed, to
obtain the results in \ref{Results}.

## Obtaining and prepariing the dataset

The data employed in this paper is based on the constituent list of the
Johannesburg All Share Index (ALSI) from January 1, 2000 to January 15
2024, which contains the list of the 164 companies with the highest
market value and liquidity. The historical price and volume data is
retrieved from Yahoo Finance and fundamental data from Bloomberg. From
historical price data obtained from Yahoo Finance, we filter stock that
have trading volume that exceed 1 000 000 shares traded per year and
exclude stock that have less than 90 percent of observations in the
historical price dataset.

To avoid large oscillations in the data, we transformed the price series
to include end of month data points thus returns calculations are based
on from the monthly data. Monthly historical prices are transformed
using simple returns and we assume that embedded in the price action are
cooperate events such as stock splits or consolidations of the shares.
Therefore there is no need to make additional transformations on the
return series to reflect corporate actions.

The measures of similarity used in this study are volatility and price
momentum. To cluster stock based on the two measures, we apply a
percentile ranking criterion on stock scores during a time period. For
price momentum, describes the causuality between relatively strong
performance and high future return and vice versa. Ranking highly
implies that strong performers and thus higher returns than weak
performers. This study defines cross sectional momentum as the trailing
6 month cumulative return [@asness2011momentum & @jegadeesh1993returns].
For volatility, using a 12 month lockback period compute the standard
deviation. The results of the ranking are shown in Table \ref{tab1}

## Stocks clustering

## Lloyd's algorithm

We employ the K-means that partitions $n$ observations into $k$ clusters
???. The goal is to minimize the within cluster sum of squares or
analytically:

$\underset{s}{\arg \min } \sum_{i=1}^k \sum_{x \in S_i}\left\|x-\mu_i\right\|^2$

where $x$ are the observations, $S=S_1, S_2, \ldots, S_k$ are the sets
of observations, and $\mu_i$ is the mean of the points in $S_i$. To
arrive at the optimum number of clusters, we utilize the most popular
algorithm called the Lloyd's algorithm that is closely followed by
@marvin2015creating, @bin2020k & @xu2010clustering.

Analytically:

Given a set of points
$\left\{x_1, \cdots x_n\right\}\left(x_i \in \mathbb{R}^m\right)$,

-   Initialize the K clusters with $\left\{C_1, \cdots C_K\right\}$ with
    centers
    $\left\{m_1, m_2, \cdots m_K\right\}\left(m_i \in \mathbb{R}^m\right)$.
    The centres are picked using the silhoutte method discussed in
    \ref{sil}

-   For all points $x_i(i \in\{1, \cdots n\})$, find the centre that
    closest based on a eucliean distance $d$. Following this, assign
    $x_i$ to the cluster corresponding to the closest centre.

$x_i \in C_j$ if
$d\left(x_i, m_j\right) \leq d\left(x_i, m_l\right) \quad(\forall l \in\{1, \cdots K\})(j \neq l)(\forall i \in\{1, \cdots n\})$.

-   Recalculate the center for each cluster $C_l(l \in\{1, \cdots K\})$.
    The new cluster centres are the mean of the points in the same
    cluster.

$m_l=\frac{1}{\left|C_l\right|} \sum_{x_p \in C_l} x_p \quad(\forall l \in\{1, \cdots K\})$.

-   Repeat processes two and three until no cluster has any change in
    point assignment.

## Silhoutte index \label{sil}

To evaluate the goodness of fit of partitioning using K means clustering
the silhoutte index is used. A summary that closely follows
@rousseeuw1987silhouettes, can be seen below:

Given $n$ data points $\left\{x_1, \cdots x_n\right\}$, a partitioning
result of $K$ cluster $\left\{C_1, \cdots C_K\right\}$ and distance
metric $d$, for each $x_i$ in cluster $C_l$, define

$a\left(x_i\right)=\frac{1}{\left|C_l\right|-1} \sum_{\forall x_j \in C_l, i \neq j} d\left(x_i, x_j\right)$

where $a(x_i)$ is the mean dissimilarity between $x_i$ to all other
points within the same cluster.

For each point $x_i$ in cluster $C_l$, define

$b\left(x_i\right)=\min _{\forall p \in\{1, \cdots K\}, p \neq l} \frac{1}{\left|C_p\right|} \sum d\left(x_i, x_j\right.)$

$b(x_i)$ is the minimum dissimilarity between $x_i$ and all points in
some $C_p$ which does not contain $x_i$.

For each point $x_i$ in cluster $C_l$, their silhoutte index is defined
as

$s\left(x_i\right)= \begin{cases}1-\frac{a\left(x_i\right)}{b\left(x_i\right)} & \text { if } a\left(x_i\right)<b\left(x_i\right) \\ 0 & \text { if } a\left(x_i\right)=b\left(x_i\right) \\ \frac{b\left(x_i\right)}{a\left(x_i\right)}-1 & \text { if } a\left(x_i\right)>b\left(x_i\right)\end{cases}$

where $s(x_i)$ ranges between $[-1, 1]$.

For $s(x_i)$ that approaches 1, it means that $a(x_i)$ needs to be
significantly smaller than $b(x_i)$, implying that within-cluster mean
dissimilarity is much less than the smallest between-cluster mean
dissimilarity, and thus the model does a good job clustering similar
points together.

For the $s(x_i)$ that approaches 0, $a(x_i)$ needs to be significantly
greater than $b(x_i)$, implying that within-cluster mean dissimilarity
is much greater than the smallest between- cluster mean dissimilarity,
and thus the model does a poor job clustering similar points together.

For this study, we choose $K$ with the highest silhoutte index/value

## Portfolio Backtest

The out-of-sample performance of cluster portfolios is compared to the benchmark, the JSE All Share Index. To manage risk exposure to a single asset or industry,  we use a cap  on each asset's allocation. Thus use a single company methodology similar to Standard & Poor Capping Methodology [@sp].
In a single company capping methodology, no company in an index (cluster in our case) is
allowed to breach a certain pre-determined weight as of each rebalancing period ^[we set the maximum weight to be that of an equally weight cluster]. Theoretically, this should preserve the within cluster diversification benefits and allow the portfolio value to either increase or decrease depending on stock performance during the quarter. We rebalance the portfolios once every three months, similar to the frequency of rebalancing conducted by the JSE on the JSE/FTSE indices, that is, re balance on the last daty of March, June, September and December. 

\newpage

# Results \label{Results}

\newpage

# References

::: {#refs}
:::

# Appendix

## Appendix A

```{r echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

ranking.df <- read_csv("data/ranking_date.csv") 

# ranking table
ranking_table <- ranking.df %>% rename( 'Volatility  Rank' = percentile_rank_vol, "Price Momentum Rank" = percentile_rank_momen) %>% select(stock, 'Volatility  Rank', "Price Momentum Rank" ) %>% mutate(stock = str_remove(stock, ".JO")) %>% rename(Ticker = stock)

data_o = ranking_table %>% tibble::as_tibble()
  addtorow          <- list()
  addtorow$pos      <- list()
  addtorow$pos[[1]] <- c(0)
  addtorow$command  <- c(paste("\\hline \n",
                               "\\endhead \n",
                               "\\hline \n",
                               "{\\footnotesize Continued on next page} \n",
                               "\\endfoot \n",
                               "\\endlastfoot \n",sep=""))

 table <- xtable(data_o, caption = "Clustering Similarity Measures\\label{tab1}")
  print.xtable(table,
             tabular.environment = "longtable",
             floating = FALSE, # Leave this as is.
             table.placement = 'H', # Leave this as is.
             booktabs = T, # Aesthetics
             include.rownames = FALSE,  # Typically you don't want this in a table.
             add.to.row = addtorow, # For adding the Continued on next page part...
             comment = FALSE,
             caption.placement = 'bottom',  # Where do you want the caption?
             size="\\fontsize{12pt}{13pt}\\selectfont"  # Size of text in table..
             )
```

## Appendix B
